Explainable AI (XAI) and Classification (SVM & KNN)
This repository contains code for Explainable AI (XAI) techniques and classification models (SVM and KNN) developed for multimodal emotion recognition using EEG and wristband data. The XAI component leverages SHAP (SHapley Additive exPlanations) and Grad-CAM (Gradient-weighted Class Activation Mapping) to interpret model decisions, revealing feature importance (e.g., EEG bandpowers, BVP/GSR signals) and temporal activations critical for emotion prediction. The SVM and KNN classifiers are implemented for comparative analysis across modalities (EEG, wristband, and combined data), with SVM achieving higher accuracy (74.8% for combined data) due to its kernel-based approach, while KNN struggles with high-dimensional features. The code integrates preprocessing, hyperparameter tuning, and evaluation metrics to ensure reproducibility and transparency, aligning with the methodologies detailed in the project report.
